from typing import List, Tuple

import torch
from torch import Tensor, nn


def reshape_input(
        x: Tensor,
        water_mask: List[Tensor],
        observed_x: Tensor,
        masked: bool = False
) -> Tuple[Tensor, Tensor, Tensor]:
    """
    Reshapes the input of the interpolation network.

    Args:
        x: The images tensor of shape (batch, observed_points, num_features, height, width)
        water_mask: A list of 1d tensors containing the indices of True values in a water mask tensor of shape
            (batch, height, width). These indices can be generated by using `torch.where(water_mask)`.
        observed_x: A tensor of shape (batch_size, observed_points, num_features, height, width) indicating which
            values in the images tensor are observed (not NaN).
        masked: Whether the interpolation is only applied to the area masked by the water_mask.

    Returns:
        A tuple containing:
            x_t: The reshaped images tensor of shape (n, num_features, observed_points) where
                n = `batch * height * width` if masked is False, `number of masked pixels` otherwise.
            d: The timestamps of each data point in the images tensor with the same shape as `x_t`.
            m: The mask of observed values with the same shape as `x_t`.
    """
    batch_size, observed_points, num_features, height, width = x.shape

    if masked:
        x_t = x.permute(0, 3, 4, 2, 1)[water_mask]
        d = torch.arange(observed_points).to(x)
        d = d[None, None, :].expand(*x_t.shape)
        m = observed_x.permute(0, 3, 4, 2, 1)[water_mask]
    else:
        x_t = x.permute(0, 3, 4, 2, 1).reshape(-1, num_features, observed_points)
        d = torch.arange(observed_points).to(x)
        d = d[None, None, :].expand(*x_t.shape)
        m = observed_x.permute(0, 3, 4, 2, 1)
        m = m.reshape(-1, num_features, observed_points)

    return x_t, d, m


def reshape_output(
        y: Tensor,
        water_mask: List[Tensor],
        batch_size: int,
        height: int,
        width: int,
        masked: bool = False
):
    """
    Reshapes the interpolated tensor to (batch_size, reference_points, 3, num_features, height, width).

    Args:
        y: The interpolated tensor of shape (3, n, num_features, reference_points) where
            n = `batch * height * width` if masked is False, `number of masked pixels` otherwise.
        water_mask: A list of 1d tensors containing the indices of True values in a water mask tensor of shape
            (batch, height, width). These indices can be generated by using `torch.where(water_mask)`.
        batch_size: The batch size.
        height: The height of the original input.
        width: The width of the original input.
        masked: Whether the interpolation was only applied to the area masked by the water_mask.

    Returns:
        The reshaped interpolated tensor of shape (batch_size, reference_points, 3, num_features, height, width).
    """
    num_features, reference_points = y[-2:]

    if masked:
        y_out = torch.zeros((batch_size, height, width, 3, num_features, reference_points))
        y_out[water_mask] = y.permute(1, 0, 2, 3)
        y_out = y_out.permute(0, 5, 3, 4, 1, 2)
    else:
        y_out = y.view(3, batch_size, height, width, num_features, reference_points)
        y_out = y_out.permute(1, 5, 0, 4, 2, 3)

    return y_out


def reshape_reconstructed_output(
        y: Tensor,
        water_mask: List[Tensor],
        batch_size: int,
        height: int,
        width: int,
        masked: bool = False
):
    """
    Reshapes the reconstructed tensor to (batch_size, observed_points, num_features, height, width).

    Args:
        y: The reconstructed tensor of shape (n, num_features, observed_points) where
            n = `batch * height * width` if masked is False, `number of masked pixels` otherwise.
        water_mask: A list of 1d tensors containing the indices of True values in a water mask tensor of shape
            (batch, height, width). These indices can be generated by using `torch.where(water_mask)`.
        batch_size: The batch size.
        height: The height of the original input.
        width: The width of the original input.
        masked: Whether the reconstruction was only applied to the area masked by the water_mask.

    Returns:
        The reshaped reconstructed tensor of shape (batch_size, observed_points, num_features, height, width).
    """
    num_features, observed_points = y[-2:]

    if masked:
        y_out = torch.zeros((batch_size, height, width, num_features, observed_points))
        y_out[water_mask] = y
        y_out = y_out.permute(0, 4, 3, 1, 2)
    else:
        y_out = y.view(batch_size, height, width, num_features, observed_points)
        y_out = y_out.permute(0, 4, 3, 1, 2)

    return y_out


class InterpolationNetwork(nn.Module):
    """
    A neural network that interpolates between observed and reference points.

    Parameters:
        num_features (int): The number of features in the input data.
        observed_points (int): The number of observed points.
        reference_points (int): The number of reference points.
    """
    def __init__(
            self,
            num_features,
            observed_points,
            reference_points
    ) -> None:
        super().__init__()

        self.num_features = num_features
        self.observed_points = observed_points
        self.reference_points = reference_points

        self.single_channel = SingleChannelInterpolation(observed_points, reference_points)
        self.cross_channel = CrossChannelInterpolation(num_features, observed_points, reference_points)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x: Tensor, reconstruction: bool = False):
        x = self.single_channel(x, reconstruction)
        x = self.sigmoid(x)
        x = self.cross_channel(x, reconstruction)
        x = self.sigmoid(x)

        return x


class SingleChannelInterpolation(nn.Module):
    """
    A neural network layer that interpolates between observed and reference points for a single channel.

    Parameters:
        observed_points (int): The number of observed points.
        reference_points (int): The number of reference points.
        kappa (float, optional): A hyperparameter that controls the strength of the transformation. Default: 10.
    """
    def __init__(
            self,
            observed_points: int,
            reference_points: int,
            kappa: float = 10
    ) -> None:
        super().__init__()

        self.observed_points = observed_points
        self.reference_points = reference_points
        self.kappa = kappa
        self.kernel = nn.Parameter(torch.zeros((self.observed_points,)))

    def forward(self, x: Tensor, reconstruction: bool = False) -> Tensor:
        x_t = x[0]
        d = x[1]
        m = x[2]

        if reconstruction:
            output_dim = self.observed_points
            ref_t = d.unsqueeze(2).expand(-1, -1, output_dim, -1)
        else:
            output_dim = self.reference_points
            ref_t = torch.linspace(0, output_dim, output_dim)[None, :].to(x_t)

        x_t = x_t.unsqueeze(-1).expand(-1, -1, -1, output_dim)
        d = d.unsqueeze(-1).expand(-1, -1, -1, output_dim)
        m = m.unsqueeze(-1).expand(-1, -1, -1, output_dim)

        norm = (d - ref_t) * (d - ref_t)
        alpha = torch.log(1 + torch.exp(self.kernel))[None, None, :, None]
        w = torch.logsumexp(-alpha * norm + torch.log(m), dim=2)
        w1 = w.unsqueeze(2).expand(-1, -1, self.observed_points, -1)
        w1 = torch.exp(-alpha * norm + torch.log(m) - w1)
        y = torch.einsum("ijkl,ijkl->ijl", w1, x_t)

        if reconstruction:
            return torch.stack((y, w))

        w_t = torch.logsumexp(-self.kappa * alpha * norm + torch.log(m), dim=2)
        w_t = w_t.unsqueeze(2).expand(-1, -1, self.observed_points, -1)
        w_t = torch.exp(-self.kappa * alpha * norm + torch.log(m) - w_t)
        y_trans = torch.einsum("ijkl,ijkl->ijl", w_t, x_t)
        return torch.stack((y, w, y_trans))


class CrossChannelInterpolation(nn.Module):
    """
    A neural network layer that interpolates between observed and reference points for multiple channels.

    Parameters:
        num_features (int): The number of features in the input data.
        observed_points (int): The number of observed points.
        reference_points (int): The number of reference points.
    """
    def __init__(
            self,
            num_features: int,
            observed_points: int,
            reference_points: int
    ) -> None:
        super().__init__()

        self.num_features = num_features
        self.observed_points = observed_points
        self.reference_points = reference_points
        self.cross_channel_interpolation = nn.Parameter(torch.eye(self.num_features))

    def forward(self, x: Tensor, reconstruction: bool = False) -> Tensor:
        output_dim = self.observed_points if reconstruction else self.reference_points

        y = x[0]
        w = x[1]

        intensity = torch.exp(w)

        y = y.permute(0, 2, 1)
        w = w.permute(0, 2, 1)
        w2 = w
        w = w.unsqueeze(-1).expand(-1, -1, -1, self.num_features)
        den = w.logsumexp(dim=2)
        w = torch.exp(w2 - den)
        mean = y.mean(dim=1)
        mean = mean[:, None, :].expand(-1, output_dim, -1)
        w2 = (w * (y - mean)) @ self.cross_channel_interpolation + mean
        rep1 = w2.permute(0, 2, 1)

        if reconstruction:
            return rep1

        y_trans = x[2]
        y_trans = y_trans - rep1
        return torch.stack((rep1, intensity, y_trans))
